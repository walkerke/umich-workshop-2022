---
title: "Using the new 2016-2020 ACS estimates in R"
author: "Kyle Walker"
date: March 25, 2022
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(tigris_use_cache = TRUE)
library(tigris)
library(tmap)
library(sf)
tmap_options(legend.text.size = 1)

knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.width = 12)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)

style_xaringan(
  title_slide_background_color = "#035004",
  text_color = "black",
  header_color = "#035004",
  inverse_background_color = "#035004",
  text_font_family = "Gotham Narrow",
  header_font_family = "Helvetica",
  header_font_weight = "bold",
  link_color = "#1a730f",
  code_inline_color = "#035004"
)
```

## About me

.pull-left[

* Associate Professor of Geography at TCU 

* Spatial data science researcher and consultant

* R package developer: __tidycensus__, __tigris__, __mapboxapi__

* Book: [_Analyzing US Census Data: Methods, Maps and Models in R_](https://walker-data.com/census-r/)
  - Available for free online right now;
  - To be published in print with CRC Press in fall 2022

]

.pull-right[

<img src=img/photo.jpeg>

]

---

## SSDAN workshop series

* March 10: an introduction to 2020 US Census data
  - [If you missed the workshop, view the slides here](https://walker-data.com/umich-workshop-2022/intro-2020-census/#1)

* Last week: Mapping 2020 Census data
  - [If you missed the workshop, view the slides here](https://walker-data.com/umich-workshop-2022/mapping-census-data/#1)

* __Right now__: a first look at the 2016-2020 American Community Survey data with R and __tidycensus__

---

## Today's agenda

* Hour 1: An overview of the 2016-2020 ACS data in R and __tidycensus__

* Hour 2: Visualizing 2016-2020 ACS data

* Hour 3: Advanced topics: margins of error & time-series analysis

---

## General setup

* Packages required for today's workshop:

```{r install-packages, eval = FALSE}
install.packages(c("tidycensus", "tidyverse", "mapview", "leafsync", "ggspatial"))
# For brand-new features:
install.packages("remotes")
remotes::install_github("walkerke/tidycensus")
```

* Other required packages will be picked up as dependencies of these packages

* Or use the pre-built RStudio Cloud environment at https://rstudio.cloud/project/3705005

---
class: middle, center, inverse

## Part 1: An overview of the 2016-2020 ACS data in R and __tidycensus__

---

## What is the American Community Survey (ACS)?

* Annual survey of 3.5 million US households 

* Covers topics not available in decennial US Census data (e.g. income, education, language, housing characteristics)

* Available as 1-year estimates (for geographies of population 65,000 and greater) and 5-year estimates (for geographies down to the block group)
  - 2020 1-year data only available as [experimental estimates](https://www.census.gov/programs-surveys/acs/data/experimental-data.html)

* Data delivered as _estimates_ characterized by _margins of error_

---

## The __tidycensus__ R package

* R interface to the Decennial Census, American Community Survey, Population Estimates Program, and Public Use Microdata Series APIs

* Key features: 
  - Wrangles Census data internally to return tidyverse-ready format (or traditional wide format if requested);
  
  - Automatically downloads and merges Census geometries to data for mapping; 
  
  - Includes tools for handling margins of error in the ACS and working with survey weights in the ACS PUMS;
  
  - States and counties can be requested by name (no more looking up FIPS codes!)

---

## ACS data in __tidycensus__

* The `get_acs()` function in __tidycensus__ allows you to access ACS data from 2005 through 2020

* Our focus today: the 2016-2020 ACS estimates, available with the argument `year = 2020`

* Other required arguments: `geography`, for the level of aggregation, and `variables`, for one or more ACS variables

* `get_acs()` defaults to the 5-year ACS with the argument `survey = "acs5"`; `survey = "acs1"` is used for 1-year ACS data

---

## Review: __tidycensus__ and the Census API

* To use tidycensus, you will need a Census API key.  Visit https://api.census.gov/data/key_signup.html to request a key, then activate the key from the link in your email.  

* Once activated, use the `census_api_key()` function to set your key as an environment variable

```{r api-key, eval = FALSE}
library(tidycensus)

census_api_key("YOUR KEY GOES HERE", install = TRUE)
```

---

## Example: population born in Mexico by state

```{r born-in-mexico}
library(tidycensus)

born_in_mexico <- get_acs(
  geography = "state", 
  variables = "B05006_150",
  year = 2020 #<<
)
```

---

```{r born-in-mexico-show}
born_in_mexico
```

---

## Example: median age by state

```{r median-age}
median_age <- get_acs(
  geography = "state",
  variables = "B01002_001",
  year = 2020 #<<
)
```

---

```{r median-age-show}
median_age
```

---

## Understanding `get_acs()` output

By default, ACS data are returned by `get_acs()` with the following five columns: 

* `GEOID`: unique identifier for the Census geographic unit

* `NAME`: A descriptive name for the geographic unit (e.g. a state name)

* `variable`: the ACS variable ID 

* `estimate`: The ACS estimate. Estimates are interpretated as _characteristics_ rather than true counts.  

* `moe`: The margin of error associated with the estimate at a 90 percent confidence level.

Using the argument `output = "wide"` will spread the estimates and MOEs across the columns of the dataset

---

## Geography and the ACS

.pull-left[

* The `geography` argument in `get_acs()` allows users to access data aggregated to varying levels of the Census hierarchy

* Geographies should be formatted [as specified in the _Analyzing US Census Data_ book](https://walker-data.com/census-r/an-introduction-to-tidycensus.html#geography-and-variables-in-tidycensus)

* ACS data available __starts at the block group__; not all variables are available for all geographies

]

.pull-right[

<img src=img/census_diagram.png>

]

---

## Example: geography aliases

* The commonly-requested "metropolitan statistical area/micropolitan statistical area" and "zip code tabulation area" geographies can be aliased as "cbsa" and "zcta", respectively

```{r cbsa-data}
median_age_cbsa <- get_acs(
  geography = "cbsa", #<<
  variables = "B01002_001",
  year = 2020
)
```

---

```{r cbsa-data-show}
median_age_cbsa
```

---

## Example: geographic subsets

* Smaller geographies (e.g. tracts, block groups) are available by state and county using `state` and `county` arguments

* Access with common names - no need for FIPS codes!

```{r geographic-subsets}
washtenaw_median_age <- get_acs(
  geography = "block group",
  variables = "B01002_001",
  state = "MI", #<<
  county = "Washtenaw", #<<
  year = 2020
)
```

---

```{r geographic-subsets-show}
washtenaw_median_age
```


---

## Variables and datasets in the 5-year ACS

* The ACS Detailed Tables, Data Profile, and Subject Tables are available with `get_acs()`; __tidycensus__ will auto-detect the dataset from the variable name and fetch from the appropriate location

* To look up variable IDs from a dataset, use: 
  - Detailed Tables: `load_variables(2020, "acs5")`
  - Data Profile: `load_variables(2020, "acs5/profile")`
  - Subject Tables: `load_variables(2020, "acs5/subject")`
  - Comparison Profile: `load_variables(2020, "acs5/cprofile")` (GitHub only)

* __New__: The `geography` column tells you the smallest geography at which a variable is available; the Data Profile and Subject tables are available at the tract and up, and the Comparison Profile is available at the county and up

---
class: middle, center, inverse

## Analyzing 2016-2020 ACS data

---

## Viewing ACS data

* Basic analysis of data in RStudio can be accomplished with the interactive table generated by `View()` (or Ctrl+click on the data object in your script)

* Example: median home value by county in the 2016-2020 ACS

```{r median-home-value}
median_home_value <- get_acs(
  geography = "county",
  variables = "B25077_001",
  year = 2020
)
```

---

## Exploring data with the tidyverse

* ACS data returned by __tidycensus__ are designed for analysis with __tidyverse__ packages like __dplyr__ 

* [Basic examples covered in the first workshop will work for ACS data as well](https://walker-data.com/umich-workshop-2022/intro-2020-census/#42)

* Example question: which counties are in the top 10 percent nationally for median home values, and how does this break down by state?

---

## Step 1: extract the top 10 percent

```{r get-top-10-percent}
library(tidyverse)

top10percent <- median_home_value %>%
  mutate(percentile = percent_rank(estimate)) %>% #<<
  filter(percentile >= 0.9) #<<
```

---

```{r show-top-10-percent}
top10percent
```

---

## Step 2: extract state information from the `NAME` column

* The `separate()` function splits a column into multiple columns based on a separator; useful for parsing the `NAME` column returned by __tidycensus__

```{r separate}
top10percent <- top10percent %>%
  separate( #<<
    NAME, #<<
    into = c("county", "state"), #<<
    sep = ", " #<<
  ) #<<
```

---

```{r show-separated}
top10percent
```

---

## Step 3: group by `state` and summarize

```{r state-summary}
state_summary <- top10percent %>%
  group_by(state) %>% #<<
  summarize(n = n()) %>% #<<
  arrange(desc(n)) #<<
```

---

```{r state-summary-show}
state_summary
```

---

## Part 1 exercises

1. Use `load_variables()` to browse the available variables in the 2016-2020 ACS.  Find a variable that interests you and try reproducing one of the examples in this section with that variable. 

2. Use the __tidyverse__ functions covered in this section to explore that variable for all counties in the US.  Which counties have the largest estimate for your variable?  Which have the smallest?

---
class: middle, center, inverse

## Part 2: Visualizing 2016-2020 ACS Data

---

## Visualization in our workshops: an overview

* In the first workshop, [we covered a range of methods using __ggplot2__ to visualize decennial US Census data](https://walker-data.com/umich-workshop-2022/intro-2020-census/#65)

* The second workshop focused on [cartography, largely with the __tmap__ package](https://walker-data.com/umich-workshop-2022/mapping-census-data/#30)

* Those methods will work for ACS data as well; we'll re-visit some of the basics here and introduce some new visualization methods with a focus on __ggplot2__

---

## __ggplot2__: a review

.pull-left[

* Graphics in __ggplot2__ are initialized with the `ggplot()` function, in which a user typically supplies a dataset and aesthetic mapping with `aes()`

* Graphical elements are then "layered" onto the ggplot object, consisting of a "geom", or geometric object (`geom_*()`) and custom styling elements linked with the `+` operator

* Example: a histogram of county median home values generated with `geom_histogram()`

]


.pull-right[

```{r histogram}
library(tidyverse)
library(scales)

ggplot(median_home_value, aes(x = estimate)) + 
  geom_histogram(bins = 30) + 
  scale_x_continuous(labels = label_dollar())
```


]

---
class: middle, center, inverse

## Example #1: visualizing margins of error

---

## Visualizing ACS estimates

* As opposed to decennial US Census data, ACS estimates include information on uncertainty, represented by the _margin of error_ in the `moe` column

* This means that in some cases, visualization of estimates without reference to the margin of error can be misleading

* Example: a sorted bar chart ([drawing from an example in the first workshop](https://walker-data.com/umich-workshop-2022/intro-2020-census/#79))

---

## Visualizing ACS estimates

.pull-left[

* Data on median household income by county can be readily acquired...

```{r nj-income}
nj_income <- get_acs(
  geography = "county",
  variables = "B19013_001",
  state = "NJ",
  year = 2020
) %>%
  mutate(NAME = str_remove(NAME, 
                           " County, New Jersey"))
```


]

--

.pull-right[

* ...and visualized comparatively with __ggplot2__

```{r nj-income-bar}
nj_income_bar <- ggplot(nj_income, 
       aes(x = estimate, 
           y = reorder(NAME, estimate))) + 
  geom_col() + 
  labs(title = "Median household income, 2016-2020 ACS", 
       subtitle = "Counties in New Jersey", 
       x = "ACS estimate", 
       y = "") + 
  theme_minimal(base_size = 18) + 
  scale_x_continuous(labels = dollar_format(scale = 0.001, 
                                            suffix = "K"))
```


]

---

```{r nj-income-bar-show}
nj_income_bar
```


---

## Problem: which county has the highest income in New Jersey?

* The chart suggests that Hunterdon County has the highest income in the state, but Morris and Somerset Counties are well within Hunterdon's margin of error

```{r head-nj-income}
nj_income %>%
  arrange(desc(estimate)) %>%
  head(3)
```

* How to visualize uncertainty in an intuitive way?

---

## Visualizing margins of error

```{r nj-income-errorbar}
nj_income_errorbar <- ggplot(nj_income, 
       aes(x = estimate, 
           y = reorder(NAME, estimate))) + 
  geom_errorbar(aes(xmin = estimate - moe, xmax = estimate + moe), #<<
                width = 0.5, size = 0.5) + #<<
  geom_point(color = "navy", size = 3) + #<<
  labs(title = "Median household income, 2016-2020 ACS", 
       subtitle = "Counties in New Jersey", 
       x = "ACS estimate", 
       y = "",
       caption = "Error bars reflect the margin of error around the ACS estimate") + #<< 
  theme_minimal(base_size = 18) + 
  scale_x_continuous(labels = dollar_format(scale = 0.001, 
                                            suffix = "K"))
```


---

```{r nj-income-errorbar-show}
nj_income_errorbar
```

---
class: middle, center, inverse

## Example #2: building population pyramids


---

## Identifying relevant data

* The ACS Data Profile and ACS Subject Tables will commonly include pre-aggregated versions of popular statistics, helping analysts avoid doing the aggregations on their own

```{r load-subject}
subject <- load_variables(2020, "acs5/subject")
```

---

## Preparing the data request

```{r prepare-data-request}
cohort_names <- c("0-4", "5-9", "10-14", "15-19",
                  "20-24", "25-29", "30-34", "35-39",
                  "40-44", "45-49", "50-54", "55-59",
                  "60-64", "65-69", "70-74", "75-79",
                  "80-84", "85+")

male_vars <- 2:19 %>%
  str_pad(2, "left", "0") %>%
  paste0("S0101_C03_0", .) %>%
  set_names(cohort_names)

female_vars <- 2:19 %>%
  str_pad(2, "left", "0") %>%
  paste0("S0101_C05_0", .) %>%
  set_names(cohort_names)
```

---

## Assembling the data

```{r get-pyramid-data}
male_data <- get_acs(
  geography = "county",
  variables = male_vars,
  state = "MI",
  county = "Washtenaw",
  year = 2020
) %>%
  mutate(sex = "Male",
         estimate = estimate * -1)

female_data <- get_acs(
  geography = "county",
  variables = female_vars,
  state = "MI",
  county = "Washtenaw",
  year = 2020
) %>%
  mutate(sex = "Female")

pyramid_data <- bind_rows(male_data, female_data) %>%
  mutate(variable = factor(variable, levels = cohort_names)) #<<

```

---

## Designing the visualization

```{r washtenaw-pyramid}
washtenaw_pyramid <- ggplot(pyramid_data, 
                            aes(x = estimate, y = variable, 
                                fill = sex)) + 
  geom_col(width = 0.95, alpha = 0.75) + 
  theme_minimal(base_size = 18) + 
  scale_x_continuous(labels = function(x) paste0(abs(x / 1000), "k")) + 
  scale_fill_manual(values = c("#00274C", "#FFCB05")) + 
  labs(x = "", 
       y = "ACS estimate", 
       title = "Population structure in Washtenaw County, Michigan", 
       fill = "", 
       caption = "Data source: 2016-2020 ACS & tidycensus R package")
```

---

```{r washtenaw-pyramid-show}
washtenaw_pyramid
```

---
class: middle, center, inverse

## Example #3: Mapping ACS data

---

## Review: mapping Census data

* [In last week's workshop](https://walker-data.com/umich-workshop-2022/mapping-census-data/#42), participants learned how to make maps of decennial Census data with a focus on the __tmap__ R package

* __tidycensus__ functions return pre-joined geometry and Census attribute data with the argument `geometry = TRUE`, helping you map data faster

* `geometry = TRUE` works with `get_acs()`!

---

## Example: using `geometry = TRUE` with `get_acs()`

```{r get-orleans-income}
orleans_income <- get_acs(
  geography = "tract",
  variables = "B19013_001",
  state = "LA",
  county = "Orleans",
  geometry = TRUE
)
```

---

```{r view-orleans-income}
orleans_income
```

---

## Example: mapping with __ggplot2__

.pull-left[

* The `geom_sf()` function in __ggplot2__ can be used to quickly make exploratory maps

* For ACS data, specify `aes(fill = estimate)` to produce a choropleth map

]

.pull-right[


```{r orleans-income-first}
ggplot(orleans_income, aes(fill = estimate)) + 
  geom_sf() 
```

]


---

## Customizing colors

.pull-left[

* A wide range of color palettes are available with the `scale_fill_*()` family of functions

* The viridis color palettes (available with `scale_fill_viridis_c()` for continuous versions) offer a series of colorblind and print-friendly palettes for mapping

]

.pull-right[

```{r orleans-income-show}
ggplot(orleans_income, aes(fill = estimate)) + 
  geom_sf() + 
  scale_fill_viridis_c(option = "mako")
```


]


---

## Refining your cartography

.pull-left[

* [As discussed in the previous workshop](https://walker-data.com/umich-workshop-2022/mapping-census-data/#82), water areas like New Orleans will look best when water area is removed

* The `erase_water()` function in the __tigris__ package handles this; use the argument `cb = FALSE` when fetching ACS data to avoid sliver polygons

]

.pull-right[

```{r orleans-erase}
library(tigris)
library(sf)

orleans_erase <- get_acs(
  geography = "tract",
  variables = "B19013_001",
  state = "LA",
  county = "Orleans",
  geometry = TRUE,
  cb = FALSE #<<
) %>%
  st_transform(26982) %>% #<<
  erase_water(area_threshold = 0.99) #<<
```


]

---

```{r orleans-erase-show}
ggplot(orleans_erase, aes(fill = estimate)) + 
  geom_sf() + 
  scale_fill_viridis_c(option = "mako")
```

---

## Adding a basemap

* The easiest way to add a basemap to a __ggplot2__ map is with `annotation_map_tile()` in the __ggspatial__ package

```{r final-map}
library(ggspatial)

final_map <- ggplot(orleans_erase, aes(fill = estimate)) + 
  annotation_map_tile(type = "cartolight", zoom = 11) + #<<
  theme_void(base_size = 20) + 
  geom_sf(alpha = 0.6, lwd = 0.1) + 
  scale_fill_viridis_c(option = "mako", labels = label_dollar()) + 
  labs(title = "Median household income, Orleans Parish LA",
       subtitle = "2016-2020 ACS estimates",
       caption = "Tile source: CARTO / OpenStreetMap contributors",
       fill = "ACS estimate  ")
```

---

```{r final-map-show}
final_map
```


---

## Part 2 exercises

1. Try re-creating one of the three charts presented in this section with a different state and/or county.  

2. Customize your chart with different colors or styles; [ggplot2 documentation on themes is found here](https://ggplot2.tidyverse.org/reference/ggtheme.html).

---
class: middle, center, inverse

## Part 3: margins of error and time-series analysis

---

## Margins of error in the 2016-2020 ACS

* As discussed earlier, __tidycensus__ will always return the margin of error for an estimate when applicable

* Due to data collection issues influenced by the COVID-19 pandemic, the 2020 ACS had a lower response rate than in previous years

* This means that margins of error are larger in the 2016-2020 ACS than in previous datasets

---

## Comparing margins of error

<img src=img/margins_of_error.png style = "width: 700px">

---

## Modifying the returned margin of error

* By default, margins of error are found in the `moe` column; in wide-form data, MOEs are found in columns that end with `M`

* The `moe_level` parameter controls the confidence level of the MOE; choose `90` (the default), `95`, or `99`

---

## Margins of error for small geographies

.pull-left[

* For small geographies like Census tracts or block groups, margins of error may be proportionally large for small populations

* Example: granular population age bands by sex for a Census tract in Salt Lake County, Utah

]


.pull-right[

```{r moe-example}
vars <- paste0("B01001_0", c(20:25, 44:49))
salt_lake <- get_acs(
  geography = "tract",
  variables = vars,
  state = "Utah",
  county = "Salt Lake",
  year = 2019
)
example_tract <- salt_lake %>%
  filter(GEOID == "49035100100")
```

]

---

## Using margin of error functions in __tidycensus__

* tidycensus includes helper functions for calculating derives margins of error based on Census-supplied formulas.  These functions include `moe_sum()`, `moe_product()`, `moe_ratio()`, and `moe_prop()`

Example: 

```{r moe-prop}
moe_prop(25, 100, 5, 3)
```

---

## Calculating derived MOEs tidyverse-style

* `moe_sum()` is designed to work within a `group_by() %>% summarize()` pipeline, calculating derived margins of error along with rolled-up estimates

```{r slc-grouped}
salt_lake_grouped <- salt_lake %>%
  mutate(sex = case_when(
    str_sub(variable, start = -2) < "26" ~ "Male",
    TRUE ~ "Female"
  )) %>%
  group_by(GEOID, sex) %>%
  summarize(sum_est = sum(estimate), 
            sum_moe = moe_sum(moe, estimate))
```

---

```{r slc-grouped-show}
salt_lake_grouped
```

---

## A note from Census on derived MOEs

* A note of caution [from the US Census Bureau](https://www2.census.gov/programs-surveys/acs/tech_docs/statistical_testing/2019_Instructions_for_Stat_Testing_ACS.pdf?): 

> All [derived MOE methods] are approximations and users should be cautious in using them. This is because these methods do not consider the correlation or covariance between the basic estimates. They may be overestimates or underestimates of the derived estimateâ€™s standard error depending on whether the two basic estimates are highly correlated in either the positive or negative direction. As a result, the approximated standard error may not match direct calculations of standard errors or calculations obtained through other methods.


---
class: middle, center, inverse

## Time-series analysis with the ACS

---

## Time-series and the ACS: some notes

* 5-year ACS data represent _overlapping survey years_, meaning that direct comparison between overlapping datasets is not typically recommended

* The Census Bureau recommends comparing non-overlapping years in the 5-year ACS

* For 2016-2020 data, available 5-year intervals for comparison are 2006-2010 and 2011-2015

---

## Getting data for multiple years

* The `map_dfr()` function in the __purrr__ package (a member of the tidyverse) is a great way to iterate over a sequence of years and return the combined result

```{r nebraska-series}
years <- c(2010, 2015, 2020)

nebraska_series <- map_dfr(years, function(year) {
  get_acs(
    geography = "county",
    state = "NE",
    variables = "B01002_001",
    year = year
  ) %>%
    mutate(year = year)
}) %>%
  arrange(NAME)
```

---

```{r nebraska-series-show}
nebraska_series
```


---

## Caution: inconsistent variable names across years

* The ACS Data Profile and Subject Tables are not guaranteed to have the same variable names across years, and not all Detailed Tables variables are available in every year

* For example: try swapping in `"DP02_0068P"` for the variable in the example above (representing % of the population age 25 and up with a bachelor's degree in 2020)

---

## New feature: comparison profile tables

.pull-left[

* In the development version of __tidycensus__, I _just added_ support for the ACS Comparison Profile

* The Comparison Profile includes data on the current 5-year ACS and the 5-year ACS that ends 5 years prior to help with time-series comparisons  

]

.pull-right[

```{r cp-tables}
ak_income_compare <- get_acs(
  geography = "county",
  variables = c(
    income15 = "CP03_2015_062",
    income20 = "CP03_2020_062"
  ),
  state = "AK",
  year = 2020
)
```


]

---

```{r cp-tables-show}
ak_income_compare
```

---

## Geography and making comparisons

* Data in the Comparison Profile tables is only available down to the county level ([though counties can change from ACS to ACS!](https://walker-data.com/umich-workshop-2022/intro-2020-census/#63))

* Comparing _neighborhood-level_ change across ACS datasets introduces additional challenges with the 2016-2020 data, as Census tract and block group boundaries differ from previous years

---

## New boundaries in the 2016-2020 data

* Locations with significant population growth (e.g. suburban Collin County, Texas) will have Census tracts / block groups with large populations subdivided in the 2020 Census

* Example: total population by Census tract in Collin County in the 2015-2019 ACS (on the left) and the 2016-2020 ACS (on the right)

---

```{r collin-compare, echo = FALSE}
library(patchwork)

ts_maps <- purrr::map_dfr(2019:2020, ~{
  dat <- get_acs(
    geography = "tract",
    variables = "B01001_001",
    state = "TX",
    county = "Collin County",
    geometry = TRUE,
    year = .x
  ) %>%
    mutate(year = .x)
})

ggplot(ts_maps, aes(fill = estimate)) + 
  geom_sf(lwd = 0.1) + 
  theme_void(base_size = 18) + 
  scale_fill_viridis_c() + 
  facet_wrap(~year)

```

---
class: middle, center, inverse

## Discussion: interpolating data between different sets of Census geographies

---

## Data setup

* Let's grab data on the population working from home by Census tract in Maricopa County, AZ

* Use a projected coordinate reference system to speed things up!

```{r get-wfh-data, eval = FALSE}
library(sf)

wfh_15 <- get_acs(geography = "tract", variables = "B08006_017", year = 2015,
                  state = "AZ", county = "Maricopa", geometry = TRUE) %>%
  st_transform(26950)

wfh_20 <- get_acs(geography = "tract", variables = "B08006_017", year = 2020,
                  state = "AZ", county = "Maricopa", geometry = TRUE) %>%
  st_transform(26950)
```

---

## Method 1: area-weighted interpolation

.pull-left[

* _Interpolating_ data between sets of boundaries involves the use of _weights_ to re-distribute data from one geography to another

* A common method is _area-weighted interpolation_, which allocates information from one geography to another weighted by the area of overlap

* Typically more accurate when going _backward_, as many new tracts will "roll up" within parent tracts from a previous Census (though not always)

]

.pull-right[

```{r areal-interpolate, eval = FALSE}
library(sf)

wfh_20_to_15 <- wfh_20 %>%
  select(estimate) %>%
  st_interpolate_aw(to = wfh_15, extensive = TRUE)
```


]

---

## Method 1: area-weighted interpolation

* Let's compare the two maps:

```{r map-aw, eval = FALSE}
library(mapview)
library(leafsync)

m20a <- mapview(wfh_20, zcol = "estimate", layer.name = "2020 geographies")
m15a <- mapview(wfh_20_to_15, zcol = "estimate", layer.name = "2015 geographies")

sync(m20a, m15a)
```


---

## Method 2: population-weighted interpolation

* If you need to go _forward_, area-weighted interpolation may be very inaccurate as it can incorrectly allocate large values to low-density / empty areas

* _Population-weighted interpolation_ will instead use an underlying dataset explaining the population distribution as weights

* Example: population-weighted interpolation using block population weights from the 2020 Census

---

## A function for population-weighted interpolation

.pull-left[

* Population-weighted interpolation is more complicated than would fit in a slide deck, so I've written a function named `interpolate_pw()` found in the companion script `population_weighted_interpolation.R`

* Let's give it a try: 

]

.pull-right[

```{r pop-interpolate, eval = FALSE}
# source("population_weighted_interpolation.R")
library(tigris)
options(tigris_use_cache = TRUE)

maricopa_blocks <- blocks(
  "AZ", 
  "Maricopa", 
  year = 2020
)

wfh_15_to_20 <- interpolate_pw(
  from = wfh_15,
  to = wfh_20,
  weights = maricopa_blocks,
  weight_column = "POP20",
  crs = 26950,
  extensive = TRUE
)
```


]

---

## Evaluating the result

* Let's compare the two maps:

```{r map-pw, eval = FALSE}
m15b <- mapview(wfh_15, zcol = "estimate", layer.name = "2015 geographies")
m20b <- mapview(wfh_15_to_20, zcol = "estimate", layer.name = "2020 geographies")

sync(m15b, m20b)
```

---

## Concluding thoughts

* While this workflow uses population-weighted interpolation, [differential privacy in the 2020 Census may introduce some inaccuracies](https://walker-data.com/umich-workshop-2022/intro-2020-census/#17)

* NHGIS uses a methodology that incorporates land cover data for adjusting data between Census years; [read through their methodology here](https://www.nhgis.org/2000-block-data-standardized-2010-geography)

---
class: middle, center, inverse

## Thank you!